{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ANzdJA-bOPaW"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import joblib  # Install joblib using pip: pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrLaodeqOToC",
        "outputId": "dd65fe90-498f-430c-99f5-5bec9d3d2120"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "dir = \"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/\"\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "nRowsRead = None\n",
        "\n",
        "# filenames = [\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
        "# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
        "\n",
        "# ]\n",
        "filenames = [\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
        "\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
        "\n",
        "]\n",
        "dfs = []\n",
        "for i in range(1, 8):  # Loop from 1 to 9 (inclusive)\n",
        "    filename = filenames[i-1]  # Access filename based on loop index\n",
        "    df = pd.read_csv(filename)\n",
        "    # df[\"DeviceName\"] = f\"PC-{i}\"  # Set device name as PC-i\n",
        "    df[\"DeviceName\"] = i  # Set device name as PC-i\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "df = pd.concat(dfs)  # Concatenate all dataframes\n",
        "\n",
        "del dfs  # Clean up temporary dataframes\n",
        "\n",
        "df.sample(10)\n",
        "\n",
        "df['DeviceName'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj56IQsvOkqw"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga2O2v7POvvA",
        "outputId": "a856e8e3-cee6-4fa0-f0c4-189522123faf"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "print(\"Column Names (excluding 'Label'):\")\n",
        "for column in df.columns:\n",
        "    if column != ' Label':\n",
        "        print(column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otbRAICDOxsq",
        "outputId": "85e2a340-2f4e-4154-e811-e9ac9da29d04"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Display unique values for labels and their counts\n",
        "print(\"\\nUnique Values and Counts for Labels:\")\n",
        "label_counts = df[' Label'].value_counts()\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Label: {label} - Count: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhm3ggjBOzVA"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "y_tmp=df[' Label'].values\n",
        "x=df.drop([' Label'], axis=1).values\n",
        "sizes=[]\n",
        "labels=[]\n",
        "for i in Counter(y_tmp):\n",
        "    tmp=str(i)+' - '+str(Counter(y_tmp)[i])\n",
        "    labels.append(tmp)\n",
        "    sizes.append(Counter(y_tmp)[i])\n",
        "# fig1, ax1 = plt.subplots(figsize = (12, 12))\n",
        "# ax1.pie(sizes,  labels = labels)\n",
        "# ax1.axis('equal')\n",
        "# plt.title('Class ratio\\n')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0T2kb2pSK-1",
        "outputId": "307d6117-df09-457e-f489-2b6a17bbc96d"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Split dataset into train and test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y_tmp, train_size=0.80, random_state=10)\n",
        "# Save X_test and Y_test to files\n",
        "joblib.dump(X_test, 'X_test.pkl')\n",
        "joblib.dump(Y_test, 'Y_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nkDpgbFR1MD"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "import traceback\n",
        "import time\n",
        "\n",
        "# Initialize Firebase Admin SDK\n",
        "cred = credentials.Certificate({\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"ioot-1fa10\",\n",
        "  \"private_key_id\": \"8888ce9b24834ba91c5a3eb00352d5eaa0ed813e\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQChiqm3TuVqj9oc\\nH6Dp0TA7XTwikAEbilA4R5LQOzcvSJDYPKR6F0kP2seDuljT8xCTR/Bxy/Za6Lfl\\nkK1VG3KpSlys2m1wNMcd1ExRDaH/EB/HaZE/JAknOTpsqWKppdKdZHBT1uU8fc/Y\\n9DR2HJ2uz8vMFAYNyBhRfrgQSImMI/lxXrn+K9w/faZLq1NYCKH5VwTaE3HYSeef\\nJkKSGJmgpujC2K6Xe6gcTZLbk8EDIEGR319t0mG8AbKQhdtZ2wpI2hZoqQnO9qx7\\nqKk+STxvCU/pJ1t4ubPyhntQi/I5FDkPC8F/jrscoICM9kcos5IKE8U3Wg4yO4c/\\najuPo15JAgMBAAECggEATkOXgSuUw8GJGvoJ5G5Ij2JW+anKF5U102Z9zyv5Swu9\\nvT34M/ynFarZ4cy9L4bCH5EJgaCfLSE1w1+KUsL3FOTlrIsw3V18oMuT4+sWcrRV\\nqS/QwoYLdzjnQPD5z5Z6yW15bG0fZ+TOd96sshKgJKshIjELU87/VTBvLdhu53lb\\nCFHeXaZs0Y+vTPeEfyyxY+bOl7ehOrB4dM0rEshyupPq98INx9v+7ucam/TZ7YYU\\nCtelEe/u+sT0QIgrzE22Uw7YoAAtTVJYle0ktepveRqr9AK8SogJ0gSuQrpc2afj\\nEGbMany5ANYS6QXrXV2BZQg5jtC4m6ivoFmg9qKnlwKBgQDXTmfY8DNR9opahhgK\\nq+tp54UYHn2UEZ667zNePPx3cLQaQfClXov5vTUvGKH1q5yr+oz47jEUim5Rqjdg\\n5+XBT+WPiRDm7I61BwhUGs0bj8QTH6du7pupDRNcFw5aKrJY9lmrkHbu+xTSW/jy\\nut0QytOzsXSxOwpD8xUD5h6ZJwKBgQDAEtsngnHtVIlMRkOeFQDOTKrchtaIbTyO\\n8rwDx/QcU1ie9f/geYP6eatZ0Nc6m11nP3MzJanVG4RVYNa1pzQbnjzCIHSfPwQf\\nwBQR/BHS4t+PNKeBQ6rp6Fw7522oV66AK1JGbaJwJvy9jcuuX41Qff4XZG0BTohG\\nvJD/yUGTDwKBgQDGbuO1BAQ4iUGQFsA3raVFMPTwesGAYxDo9qZgN1Lz/fJvtNBG\\niTH21NQceNZkJms58axVjKm9ZawxJfDuJiwRk0JenJPwUJth6n5ZjW319fVfLrBQ\\nxCbAkmWCXVmD7o/6/+k6/uUuckgJbGyvwVsXK+gbV/TVlzVp1LJMqp0OxwKBgDf7\\nxwDnFonUYAhpWoATIx7+XbbVXmZ5YHNR8NcxSseOy3/Zt/EXug4htH4DTxh3/GuB\\npPQ9gBjrYlD4XtynlZqPLqpuh097MJqIg9ESJafQFNVKxZ/5tzFiVq/nLqEonWYi\\nOmLoxbXmxzgAwmNa2nehoZPz44nD+BiWEbVcVc6lAoGBAJSPcYDlhmGKpkVAkcKK\\n8D5QUarwskk68JrJmNpoQ4g7ET/yC5ealmf/RJx1vqPIn7Li8n80vCtTNyskNaPm\\n3yet8vH8d7XF2D2MXhqqbRKVdl3B5/+AgTnuesvCHyi6jjshS/sZykTLaGGfPviq\\nXmjSszN1+EU/oxGD+eFZmfXj\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-bsj74@ioot-1fa10.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"105466721146540439823\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-bsj74%40ioot-1fa10.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "})  # Update with your Firebase Admin SDK key path\n",
        "# firebase_admin.initialize_app(cred)\n",
        "\n",
        "\n",
        "# Initialize Firebase Admin SDK\n",
        "#cred = credentials.Certificate(\"iot-firebase-adminsdk.json\")  # Update with your Firebase Admin SDK key path\n",
        "firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()\n",
        "\n",
        "# Mock data or replace with actual values as needed\n",
        "model_id = \"nP4M8mIYAP\"\n",
        "model_parameters = \"{'param1': 0.5, 'param2': 'value'}\"\n",
        "model_training_data = \"Training dataset used\"\n",
        "model_type = \"anomaly_detection\"\n",
        "\n",
        "# Load the previously saved model from the specified path\n",
        "model_path = \"drive/MyDrive/Colab Notebooks/saved_models/IOTModel.pkl\"  # Update this with your model's path\n",
        "\n",
        "try:\n",
        "    loaded_model = joblib.load(model_path)\n",
        "except Exception as e:\n",
        "    print(\"Error loading model:\", e)\n",
        "    print(traceback.format_exc())  # Print detailed traceback for debugging\n",
        "    loaded_model = None\n",
        "\n",
        "# Check if the model loaded successfully\n",
        "if loaded_model is not None:\n",
        "    # Load X_test and Y_test from files (mock data)\n",
        "    X_test = joblib.load('X_test.pkl')\n",
        "    Y_test = joblib.load('Y_test.pkl')\n",
        "\n",
        "    # Make predictions with the loaded model\n",
        "    predictions = loaded_model.predict(X_test)\n",
        "\n",
        "    # Create a DataFrame to compare predicted and actual labels\n",
        "    results_df = pd.DataFrame({\n",
        "        'Predicted': predictions,\n",
        "        'Actual': Y_test,\n",
        "        'Features': X_test.tolist()  # Converting to list for easier visualization\n",
        "    })\n",
        "\n",
        "    # Group by 'Predicted' and take up to 15 samples from each group\n",
        "    limited_results_df = results_df.groupby('Predicted').apply(lambda x: x.head(20)).reset_index(drop=True)\n",
        "\n",
        "    # Initialize an empty dictionary to store results device-wise\n",
        "    device_results = {}\n",
        "\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for _, row in limited_results_df.iterrows():\n",
        "        device_identifier = row['Features'][-1]  # Assuming last feature is device identifier\n",
        "\n",
        "        # Create a list to store prediction and actual values for this device (if not already present)\n",
        "        if device_identifier not in device_results:\n",
        "            device_results[device_identifier] = []\n",
        "\n",
        "        # Add the current prediction and actual values to the device's list\n",
        "        device_results[device_identifier].append({\n",
        "            \"Predicted\": row['Predicted'],\n",
        "            \"Actual\": row['Actual'],\n",
        "        })\n",
        "\n",
        "    # Function to save predicted data and related information to Firestore\n",
        "    def save_predicted_data_to_firestore():\n",
        "        for device_identifier, results in device_results.items():\n",
        "            for result in results:\n",
        "                # Save predicted data\n",
        "                predicted_data = {\n",
        "                    \"DeviceIdentifier\": f\"PC {device_identifier}\",\n",
        "                    \"PredictedLabel\": result['Predicted'],\n",
        "                    \"ActualLabel\": result['Actual'],\n",
        "                    \"Timestamp\": firestore.SERVER_TIMESTAMP\n",
        "                }\n",
        "                db.collection('PredictedData').add(predicted_data)\n",
        "                print(f\"Predicted data for {device_identifier} saved to Firestore.\")\n",
        "\n",
        "                # Save related data in MachineLearningModels\n",
        "                model_data = {\n",
        "                    \"DeviceID\": f\"PC {device_identifier}\",\n",
        "                    \"ModelID\": model_id,\n",
        "                    \"ModelParameters\": model_parameters,\n",
        "                    \"ModelTrainingData\": model_training_data,\n",
        "                    \"ModelType\": model_type\n",
        "                }\n",
        "                db.collection('MachineLearningModels').add(model_data)\n",
        "                print(f\"Model data for {device_identifier} saved to Firestore.\")\n",
        "\n",
        "                # Save related data in SecurityEvents\n",
        "                event_data = {\n",
        "                    \"DeviceIdentifier\": f\"PC {device_identifier}\",\n",
        "                    \"EventID\": str(uuid.uuid4()),  # Generate a unique EventID\n",
        "                    \"EventSeverity\": \"high\" if result['Predicted'] == 'BENIGN' else 'low',  # Adjust based on your criteria\n",
        "                    \"EventTimestamp\": firestore.SERVER_TIMESTAMP,\n",
        "                    \"EventType\": \"fire_alarm\"  # Example event type, adjust as needed\n",
        "                }\n",
        "                db.collection('SecurityEvents').add(event_data)\n",
        "                print(f\"Security event for {device_identifier} saved to Firestore.\")\n",
        "\n",
        "                alert_data = {\n",
        "                    \"AlertID\": str(uuid.uuid4()),  # Generate a unique ID\n",
        "                    \"AlertMessage\": \"Alert message here...\",\n",
        "                    \"AlertSeverity\": \"low\" if result['Predicted'] == 'BENIGN' else 'high',  # Adjust based on your criteria\n",
        "                    \"AlertTimestamp\": firestore.SERVER_TIMESTAMP,\n",
        "                    \"AlertType\": result['Predicted'],\n",
        "                    \"DeviceIdentifier\": f\"PC {device_identifier}\"  # Fixed concatenation\n",
        "                }\n",
        "                db.collection('SecurityAlerts').add(alert_data)\n",
        "                print(f\"PC {device_identifier}\")\n",
        "                print(f\"Security alert for {device_identifier} saved to Firestore.\")\n",
        "                time.sleep(10)\n",
        "\n",
        "    # Loop to add predicted data and related information every 10 seconds\n",
        "    while True:\n",
        "        save_predicted_data_to_firestore()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "u3eUIwitB3zh",
        "outputId": "7d19563e-df28-45bb-903b-56d5c40890ed"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def delete_collection(collection_name, batch_size):\n",
        "    collection_ref = db.collection(collection_name)\n",
        "    docs = collection_ref.limit(batch_size).stream()\n",
        "\n",
        "    deleted = 0\n",
        "\n",
        "    for doc in docs:\n",
        "        doc.reference.delete()\n",
        "        deleted += 1\n",
        "\n",
        "    if deleted >= batch_size:\n",
        "        return delete_collection(collection_name, batch_size)\n",
        "\n",
        "# Specify the collections to delete and batch size\n",
        "collections_to_delete = ['PredictedData', 'MachineLearningModels', 'SecurityEvents', 'SecurityAlerts']\n",
        "batch_size = 10  # Adjust batch size as needed\n",
        "\n",
        "# Delete each collection\n",
        "for collection in collections_to_delete:\n",
        "    delete_collection(collection, batch_size)\n",
        "\n",
        "print(\"Collections deleted successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
