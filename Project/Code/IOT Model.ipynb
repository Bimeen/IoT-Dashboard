{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7869,"status":"ok","timestamp":1718146978686,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"ANzdJA-bOPaW"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'sklearn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","from collections import Counter\n","import math\n","import tensorflow as tf\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.manifold import TSNE\n","from scipy.stats import randint, uniform\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from itertools import combinations\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import joblib   # \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70664,"status":"ok","timestamp":1718147049348,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"RrLaodeqOToC","outputId":"ecfa44ed-7a2d-4bde-a682-bf761a977a5f"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirname, _, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","dir = \"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/\"\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","\n","nRowsRead = None\n","\n","# filenames = [\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files)/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n","# \"/content/drive/MyDrive/dataset/archive (1).zip (Unzipped Files) (1)/MachineLearningCSV/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n","\n","# ]\n","filenames = [\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n","\"/content/drive/MyDrive/Colab Notebooks/CICIDS2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n","\n","]\n","dfs = []\n","for i in range(1, 8):  # Loop from 1 to 9 (inclusive)\n","    filename = filenames[i-1]  # Access filename based on loop index\n","    df = pd.read_csv(filename)\n","    # df[\"DeviceName\"] = f\"PC-{i}\"  # Set device name as PC-i\n","    df[\"DeviceName\"] = i  # Set device name as PC-i\n","\n","    dfs.append(df)\n","\n","df = pd.concat(dfs)  # Concatenate all dataframes\n","\n","del dfs  # Clean up temporary dataframes\n","\n","df.sample(10)\n","\n","df['DeviceName'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5325,"status":"ok","timestamp":1718147054669,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"nj56IQsvOkqw"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":547,"status":"ok","timestamp":1718147055213,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"ga2O2v7POvvA","outputId":"cd96f471-6894-44f5-8e81-93c543881881"},"outputs":[{"name":"stdout","output_type":"stream","text":["Column Names (excluding 'Label'):\n"]},{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn Names (excluding \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Label\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(column)\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["print(\"Column Names (excluding 'Label'):\")\n","for column in df.columns:\n","    if column != ' Label':\n","        print(column)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718147055533,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"otbRAICDOxsq","outputId":"3d271aa1-9719-4dfe-ff7b-cd20ed4acef2"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# Display unique values for labels and their counts\n","print(\"\\nUnique Values and Counts for Labels:\")\n","label_counts = df[' Label'].value_counts()\n","for label, count in label_counts.items():\n","    print(f\"Label: {label} - Count: {count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9303,"status":"ok","timestamp":1718147064832,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"fhm3ggjBOzVA"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["y_tmp=df[' Label'].values\n","x=df.drop([' Label'], axis=1).values\n","sizes=[]\n","labels=[]\n","for i in Counter(y_tmp):\n","    tmp=str(i)+' - '+str(Counter(y_tmp)[i])\n","    labels.append(tmp)\n","    sizes.append(Counter(y_tmp)[i])\n","# fig1, ax1 = plt.subplots(figsize = (12, 12))\n","# ax1.pie(sizes,  labels = labels)\n","# ax1.axis('equal')\n","# plt.title('Class ratio\\n')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10076,"status":"ok","timestamp":1718147074905,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"A0T2kb2pSK-1","outputId":"0cc831ab-5acd-430e-e29e-2e93dc8c1db3"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# Split dataset into train and test\n","X_train, X_test, Y_train, Y_test = train_test_split(x, y_tmp, train_size=0.70, random_state=10)\n","# Save X_test and Y_test to files\n","joblib.dump(X_test, 'X_test.pkl')\n","joblib.dump(Y_test, 'Y_test.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28032,"status":"ok","timestamp":1718147523930,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"9nkDpgbFR1MD","outputId":"6c30c781-8498-4b8c-93fe-0224fe689d89"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["import joblib\n","import pandas as pd\n","import uuid\n","from datetime import datetime\n","import firebase_admin\n","from firebase_admin import credentials, firestore\n","\n","# Initialize Firebase Admin SDK\n","cred = credentials.Certificate({\n","  \"type\": \"service_account\",\n","  \"project_id\": \"ioot-1fa10\",\n","  \"private_key_id\": \"8888ce9b24834ba91c5a3eb00352d5eaa0ed813e\",\n","  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQChiqm3TuVqj9oc\\nH6Dp0TA7XTwikAEbilA4R5LQOzcvSJDYPKR6F0kP2seDuljT8xCTR/Bxy/Za6Lfl\\nkK1VG3KpSlys2m1wNMcd1ExRDaH/EB/HaZE/JAknOTpsqWKppdKdZHBT1uU8fc/Y\\n9DR2HJ2uz8vMFAYNyBhRfrgQSImMI/lxXrn+K9w/faZLq1NYCKH5VwTaE3HYSeef\\nJkKSGJmgpujC2K6Xe6gcTZLbk8EDIEGR319t0mG8AbKQhdtZ2wpI2hZoqQnO9qx7\\nqKk+STxvCU/pJ1t4ubPyhntQi/I5FDkPC8F/jrscoICM9kcos5IKE8U3Wg4yO4c/\\najuPo15JAgMBAAECggEATkOXgSuUw8GJGvoJ5G5Ij2JW+anKF5U102Z9zyv5Swu9\\nvT34M/ynFarZ4cy9L4bCH5EJgaCfLSE1w1+KUsL3FOTlrIsw3V18oMuT4+sWcrRV\\nqS/QwoYLdzjnQPD5z5Z6yW15bG0fZ+TOd96sshKgJKshIjELU87/VTBvLdhu53lb\\nCFHeXaZs0Y+vTPeEfyyxY+bOl7ehOrB4dM0rEshyupPq98INx9v+7ucam/TZ7YYU\\nCtelEe/u+sT0QIgrzE22Uw7YoAAtTVJYle0ktepveRqr9AK8SogJ0gSuQrpc2afj\\nEGbMany5ANYS6QXrXV2BZQg5jtC4m6ivoFmg9qKnlwKBgQDXTmfY8DNR9opahhgK\\nq+tp54UYHn2UEZ667zNePPx3cLQaQfClXov5vTUvGKH1q5yr+oz47jEUim5Rqjdg\\n5+XBT+WPiRDm7I61BwhUGs0bj8QTH6du7pupDRNcFw5aKrJY9lmrkHbu+xTSW/jy\\nut0QytOzsXSxOwpD8xUD5h6ZJwKBgQDAEtsngnHtVIlMRkOeFQDOTKrchtaIbTyO\\n8rwDx/QcU1ie9f/geYP6eatZ0Nc6m11nP3MzJanVG4RVYNa1pzQbnjzCIHSfPwQf\\nwBQR/BHS4t+PNKeBQ6rp6Fw7522oV66AK1JGbaJwJvy9jcuuX41Qff4XZG0BTohG\\nvJD/yUGTDwKBgQDGbuO1BAQ4iUGQFsA3raVFMPTwesGAYxDo9qZgN1Lz/fJvtNBG\\niTH21NQceNZkJms58axVjKm9ZawxJfDuJiwRk0JenJPwUJth6n5ZjW319fVfLrBQ\\nxCbAkmWCXVmD7o/6/+k6/uUuckgJbGyvwVsXK+gbV/TVlzVp1LJMqp0OxwKBgDf7\\nxwDnFonUYAhpWoATIx7+XbbVXmZ5YHNR8NcxSseOy3/Zt/EXug4htH4DTxh3/GuB\\npPQ9gBjrYlD4XtynlZqPLqpuh097MJqIg9ESJafQFNVKxZ/5tzFiVq/nLqEonWYi\\nOmLoxbXmxzgAwmNa2nehoZPz44nD+BiWEbVcVc6lAoGBAJSPcYDlhmGKpkVAkcKK\\n8D5QUarwskk68JrJmNpoQ4g7ET/yC5ealmf/RJx1vqPIn7Li8n80vCtTNyskNaPm\\n3yet8vH8d7XF2D2MXhqqbRKVdl3B5/+AgTnuesvCHyi6jjshS/sZykTLaGGfPviq\\nXmjSszN1+EU/oxGD+eFZmfXj\\n-----END PRIVATE KEY-----\\n\",\n","  \"client_email\": \"firebase-adminsdk-bsj74@ioot-1fa10.iam.gserviceaccount.com\",\n","  \"client_id\": \"105466721146540439823\",\n","  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n","  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n","  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n","  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-bsj74%40ioot-1fa10.iam.gserviceaccount.com\",\n","  \"universe_domain\": \"googleapis.com\"\n","})  # Update with your Firebase Admin SDK key path\n","# firebase_admin.initialize_app(cred)\n","db = firestore.client()\n","\n","# Load the previously saved model from the specified path\n","model_path = \"drive/MyDrive/Colab Notebooks/saved_models/IOTModel.pkl\"  # Update this with your model's path\n","loaded_model = joblib.load(model_path)  # Load the model\n","\n","# Load X_test and Y_test from files\n","X_test = joblib.load('X_test.pkl')\n","Y_test = joblib.load('Y_test.pkl')\n","\n","# Make predictions with the loaded model\n","predictions = loaded_model.predict(X_test)\n","\n","# Create a DataFrame to compare predicted and actual labels\n","results_df = pd.DataFrame({\n","    'Predicted': predictions,\n","    'Actual': Y_test,\n","    'Features': X_test.tolist()  # Converting to list for easier visualization\n","})\n","\n","# Group by 'Predicted' and take up to 15 samples from each group\n","limited_results_df = results_df.groupby('Predicted').apply(lambda x: x.head(15)).reset_index(drop=True)\n","\n","# Initialize an empty dictionary to store results device-wise\n","device_results = {}\n","\n","# Iterate through each row in the DataFrame\n","for _, row in limited_results_df.iterrows():\n","    device_identifier = row['Features'][-1]  # Adjust this according to your features' structure\n","\n","    # Create a list to store prediction and actual values for this device (if not already present)\n","    if device_identifier not in device_results:\n","        device_results[device_identifier] = []\n","\n","    # Add the current prediction and actual values to the device's list\n","    device_results[device_identifier].append({\n","        \"Predicted\": row['Predicted'],\n","        \"Actual\": row['Actual'],\n","    })\n","\n","# Iterate through the results and add to Firebase\n","for device_identifier, results in device_results.items():\n","    for result in results:\n","        alert_data = {\n","            \"AlertID\": str(uuid.uuid4()),  # Generate a unique ID\n","            \"AlertMessage\": \"Alert message here...\",\n","            \"AlertSeverity\": \"low\" if result['Predicted'] == 'BENIGN' else 'high',  # Adjust based on your criteria\n","            \"AlertTimestamp\": firestore.SERVER_TIMESTAMP,\n","            \"AlertType\": result['Predicted'],\n","            \"DeviceIdentifier\": f\"PC {device_identifier}\"  # Fixed concatenation\n","        }\n","        db.collection('SecurityAlerts').add(alert_data)\n","\n","print(\"Alerts have been added to Firebase.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1718147084095,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"0Qgxh61yO1Hx"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# # Split dataset into train and test\n","# X_train, X_test, Y_train, Y_test = train_test_split(x, y_tmp, train_size=0.70, random_state=10)\n","\n","# # Train Decision Tree Model\n","# DTC_Classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n","# model = DTC_Classifier.fit(X_train, Y_train)\n","\n","\n","# # Evaluate Decision Tree Model on the training set\n","# accuracy_train = metrics.accuracy_score(Y_train, DTC_Classifier.predict(X_train))\n","# confusion_matrix_train = metrics.confusion_matrix(Y_train, DTC_Classifier.predict(X_train))\n","# classification_train = metrics.classification_report(Y_train, DTC_Classifier.predict(X_train))\n","\n","# print('============================== Decision Tree Model Training Results ==============================')\n","# print(\"Model Accuracy:\" \"\\n\", accuracy_train)\n","# # print(\"Confusion matrix:\" \"\\n\", confusion_matrix_train)\n","# print(\"Classification report:\" \"\\n\", classification_train)\n","# # Display Confusion Matrix for Training Set\n","# plt.figure(figsize=(10, 8))\n","# sns.heatmap(confusion_matrix_train, annot=True, fmt='d', cmap='crest')\n","# plt.title('Confusion Matrix - Training Set')\n","# plt.ylabel('Actual Values')\n","# plt.xlabel('Predicted Values')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1718147084096,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"THaqAvumO5oP"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# # Validate Decision Tree Model on the test set\n","# accuracy_test = metrics.accuracy_score(Y_test, DTC_Classifier.predict(X_test))\n","# confusion_matrix_test = metrics.confusion_matrix(Y_test, DTC_Classifier.predict(X_test))\n","# classification_test = metrics.classification_report(Y_test, DTC_Classifier.predict(X_test))\n","\n","\n","# print('============================== Decision Tree Model Test Results ==============================')\n","# print(\"Model Accuracy:\" \"\\n\", accuracy_test)\n","# # print(\"Confusion matrix:\" \"\\n\", confusion_matrix_test)\n","# print(\"Classification report:\" \"\\n\", classification_test)\n","# # Display Confusion Matrix for Test Set\n","# plt.figure(figsize=(10, 8))\n","# sns.heatmap(confusion_matrix_test, annot=True, fmt='d', cmap='crest')\n","# plt.title('Confusion Matrix - Test Set')\n","# plt.ylabel('Actual Values')\n","# plt.xlabel('Predicted Values')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1718147084096,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"Go7P2YtBPECh"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# # Assuming you have a new set of data for prediction, let's call it X_new\n","# # Replace X_new with the actual data you want to predict on\n","# # For example, if you want to predict on the test set:\n","# X_new = X_test\n","\n","# # Make predictions using the Decision Tree model\n","# pred_dt = DTC_Classifier.predict(X_new)\n","\n","# # Create a DataFrame to display each test case with its predicted and actual labels\n","# predictions_df = pd.DataFrame({'Predicted': pred_dt, 'Actual': Y_test, 'Features': X_test.tolist()})\n","\n","# # Display the first 50 test cases with predicted and actual labels - Features: {row['Features']}\n","# for index, row in predictions_df.head(150).iterrows():\n","#     print(f\"Test Case {index + 1} - Predicted: {row['Predicted']} - Actual: {row['Actual']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1718147084096,"user":{"displayName":"Amr Fathy","userId":"05162769941019578350"},"user_tz":-180},"id":"EtxDC59EOkK4"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '\"c:/Users/Bimeen Nader/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# import os\n","\n","# # Create a directory to save the model (if it doesn't exist)\n","# os.makedirs(\"drive/MyDrive/Colab Notebooks/saved_models\", exist_ok=True)  # Creates \"saved_models\" directory if not there\n","# # Save the model using joblib\n","# joblib.dump(model, \"drive/MyDrive/Colab Notebooks/saved_models/IOTModel.pkl\")  # Replace with your desired filename\n","# print(f\"Model saved successfully to saved_models/IOTModel.pkl\")  # Update filename reference"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN6PHhwor1PVtDHph2SC5KK","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
